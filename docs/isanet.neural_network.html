

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>isanet.neural_network &mdash; IsaNet ML Lib 0.1 beta documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="isanet.optimizer" href="isanet.optimizer.html" />
    <link rel="prev" title="isanet.model_selection" href="isanet.model_selection.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> IsaNet ML Lib
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Modules:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="isanet.activation.html">isanet.activation</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.datasets.html">isanet.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.metrics.html">isanet.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.model.html">isanet.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.model_selection.html">isanet.model_selection</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">isanet.neural_network</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.optimizer.html">isanet.optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="isanet.utils.html">isanet.utils</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">IsaNet ML Lib</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>isanet.neural_network</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/isanet.neural_network.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-isanet.neural_network">
<span id="isanet-neural-network"></span><h1>isanet.neural_network<a class="headerlink" href="#module-isanet.neural_network" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="isanet.neural_network.MLPClassifier">
<em class="property">class </em><code class="sig-prename descclassname">isanet.neural_network.</code><code class="sig-name descname">MLPClassifier</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_dim</span></em>, <em class="sig-param"><span class="n">out_dim</span></em>, <em class="sig-param"><span class="n">n_layer_units</span><span class="o">=</span><span class="default_value">[100]</span></em>, <em class="sig-param"><span class="n">activation</span><span class="o">=</span><span class="default_value">'relu'</span></em>, <em class="sig-param"><span class="n">kernel_regularizer</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_epoch</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">learning_rate</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">momentum</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">nesterov</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">early_stop</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">isanet.neural_network.__BaseMLP</span></code></p>
<p>Multi-layer Perceptron classifier.</p>
<p>This model optimizes the MSE function using the stochastic gradient descent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em><em>, </em><em>no default value mandatory parameter</em>) – allows you to specify the number of inputs on the input layer</p></li>
<li><p><strong>out_dim</strong> (<em>int</em><em>, </em><em>no default value mandatory parameter</em>) – allows you to specify the number of outputs on the output layer</p></li>
<li><p><strong>hidden_layer_sizes</strong> (<em>list</em><em>, </em><em>default=</em><em>[</em><em>100</em><em>]</em>) – <p>The ith element of the list represents the number of neurons in the ith
hidden layer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">E</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">]</span> <span class="n">means</span> <span class="mi">3</span> <span class="n">hidden</span> <span class="n">layers</span> <span class="k">with</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span> <span class="ow">and</span> <span class="mi">60</span> <span class="n">neurons</span> <span class="n">respectively</span><span class="o">.</span>
</pre></div>
</div>
</p></li>
<li><p><strong>activation</strong> (<em>{'identity'</em><em>, </em><em>'sigmoid'</em><em>, </em><em>'tanh'</em><em>, </em><em>'relu'}</em><em>, </em><em>default='relu'</em>) – <p>Activation function available for the hidden layer.</p>
<ul>
<li><p>’identity’, no-op activation, useful to implement linear bottleneck,
returns f(x) = x</p></li>
<li><p>’sigmoid’, the logistic sigmoid function,
returns f(x) = 1 / (1 + exp(-x)).</p></li>
<li><p>’tanh’, the hyperbolic tan function,
returns f(x) = tanh(x).</p></li>
<li><p>’relu’, the rectified linear unit function,
returns f(x) = max(0, x)</p></li>
</ul>
</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>float</em><em>, </em><em>default=0.0001</em>) – Tikhonov regularization term, L2 penalty parameter.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default='None'</em>) – Size of minibatches for the SGD optimizer.
When set to “none”, the SGD will performe a full batch.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>default=0.1</em>) – The constant value that will be used by the SGD optimizer as learning rate</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>default=0.9</em>) – Momentum for gradient descent update. Should be between 0 and 1.</p></li>
<li><p><strong>nesterovs_momentum</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to use Nesterov’s momentum. If the momentum == 0 this parameter
is useless.</p></li>
<li><p><strong>sigma</strong> (<em>float</em><em>, </em><em>default=None</em>) – Parameter of the Super Accelerated Nesterov’s momentum.
If ‘nesterov’ is True and ‘sigma’ equals to ‘momentum’, then we have the
simple Nesterov momentum. Instead, if ‘sigma’ is different from
‘momentum’, we have the super accelerated Nesterov.</p></li>
<li><p><strong>max_epoch</strong> (<em>int</em><em>, </em><em>default=1000</em>) – It will set the Maximum number of Epoch for the SGD optimizer.
The solver iterates until convergence (determined by ‘tol’) or this number of iterations.</p></li>
<li><p><strong>early_stopping</strong> (<em>bool</em><em> or </em><em>isanet.optimizer.EarlyStopping</em><em>, </em><em>default=False</em>) – When set to False it will only use the <code class="docutils literal notranslate"><span class="pre">max_epoch</span></code> to finish training.
Otherwise, an EarlyStopping type object has been passed and will stop
training if the model goes overfitting after a number of consecutive iterations.
See docs in optimizier module.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – If int, random_state is the seed used by numpy random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to print progress messages to stdout.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>MLPClassifier provides a high-level interface capable of biting a neural network
using the parameters passed to the class as hyper parameters.</p>
<p>It can also have a regularization term added to prevent overfitting.</p>
<p>Numpy arrays of floating point values are used to store all the data under the hood.
this This matrix implementation allowed us to speed up the computation compared to an
object-oriented structure, this was possible thanks to Numpy that is able to perform
matrix operation in an efficient way by parallelizes each operation.
Numpy use optimized math routines, written in C or Fortran, for linear algebra operation
as: Blas, OpenBlas or Intel Math Kernel Library (MKL).</p>
<dl class="py method">
<dt id="isanet.neural_network.MLPClassifier.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">X_train</span></em>, <em class="sig-param"><span class="n">Y_train</span></em>, <em class="sig-param"><span class="n">X_val</span></em>, <em class="sig-param"><span class="n">Y_val</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model to data matrix X_train and target(s) Y_train and
evaluates it on the validation set (X_val, Y_val).</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPClassifier.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the multi-layer perceptron classifier.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPClassifier.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameters of the multi-layer perceptron.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPClassifier.get_history">
<code class="sig-name descname">get_history</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier.get_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the history of the multi-layer perceptron.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPClassifier.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPClassifier.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the weights of the multi-layer perceptron.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="isanet.neural_network.MLPRegressor">
<em class="property">class </em><code class="sig-prename descclassname">isanet.neural_network.</code><code class="sig-name descname">MLPRegressor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_dim</span></em>, <em class="sig-param"><span class="n">out_dim</span></em>, <em class="sig-param"><span class="n">n_layer_units</span><span class="o">=</span><span class="default_value">[100]</span></em>, <em class="sig-param"><span class="n">activation</span><span class="o">=</span><span class="default_value">'relu'</span></em>, <em class="sig-param"><span class="n">kernel_regularizer</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_epoch</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">learning_rate</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">momentum</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">nesterov</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">early_stop</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">isanet.neural_network.__BaseMLP</span></code></p>
<p>Multi-layer Perceptron regressor.</p>
<p>This model optimizes the MSE function using the stochastic gradient descent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em><em>, </em><em>no default value mandatory parameter</em>) – allows you to specify the number of inputs on the input layer</p></li>
<li><p><strong>out_dim</strong> (<em>int</em><em>, </em><em>no default value mandatory parameter</em>) – allows you to specify the number of outputs on the output layer</p></li>
<li><p><strong>hidden_layer_sizes</strong> (<em>list</em><em>, </em><em>default=</em><em>[</em><em>100</em><em>]</em>) – <p>The ith element of the list represents the number of neurons in the ith
hidden layer.</p>
<blockquote>
<div><p>E.g. [20, 40, 60] means 3 hidden layers with 20, 40 and 60 neurons respectively</p>
</div></blockquote>
</p></li>
<li><p><strong>activation</strong> (<em>{'identity'</em><em>, </em><em>'sigmoid'</em><em>, </em><em>'tanh'</em><em>, </em><em>'relu'}</em><em>, </em><em>default='relu'</em>) – <p>Activation function available for the hidden layer.</p>
<ul>
<li><p>’identity’, no-op activation, useful to implement linear bottleneck,
returns f(x) = x</p></li>
<li><p>’sigmoid’, the logistic sigmoid function,
returns f(x) = 1 / (1 + exp(-x)).</p></li>
<li><p>’tanh’, the hyperbolic tan function,
returns f(x) = tanh(x).</p></li>
<li><p>’relu’, the rectified linear unit function,
returns f(x) = max(0, x)</p></li>
</ul>
</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>float</em><em>, </em><em>default=0.0001</em>) – Tikhonov regularization term, L2 penalty parameter.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default='None'</em>) – Size of minibatches for the SGD optimizer.
When set to “none”, the SGD will performe a full batch.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>default=0.1</em>) – The constant value that will be used by the SGD optimizer as learning rate</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>default=0.9</em>) – Momentum for gradient descent update. Should be between 0 and 1.</p></li>
<li><p><strong>nesterovs_momentum</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to use Nesterov’s momentum. If the momentum == 0 this parameter
is useless.</p></li>
<li><p><strong>sigma</strong> (<em>float</em><em>, </em><em>default=None</em>) – Parameter of the Super Accelerated Nesterov’s momentum.
If ‘nesterov’ is True and ‘sigma’ equals to ‘momentum’, then we have the
simple Nesterov momentum. Instead, if ‘sigma’ is different from
‘momentum’, we have the super accelerated Nesterov.</p></li>
<li><p><strong>max_epoch</strong> (<em>int</em><em>, </em><em>default=1000</em>) – It will set the Maximum number of Epoch for the SGD optimizer.
The solver iterates until convergence (determined by ‘tol’) or this number of iterations.</p></li>
<li><p><strong>early_stopping</strong> (<em>bool</em><em> or </em><em>isanet.optimizer.EarlyStopping</em><em>, </em><em>default=False</em>) – When set to False it will only use the <code class="docutils literal notranslate"><span class="pre">max_epoch</span></code> to finish training.
Otherwise, an EarlyStopping type object has been passed and will stop
training if the model goes overfitting after a number of consecutive iterations.
See docs in optimizier module.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – If int, random_state is the seed used by numpy random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to print progress messages to stdout.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>MLPRegressor provides a high-level interface capable of biting a neural network
using the parameters passed to the class as hyper parameters.</p>
<p>It can also have a regularization term added to prevent overfitting.</p>
<p>Numpy arrays of floating point values are used to store all the data under the hood.
this This matrix implementation allowed us to speed up the computation compared to an
object-oriented structure, this was possible thanks to Numpy that is able to perform
matrix operation in an efficient way by parallelizes each operation.
Numpy use optimized math routines, written in C or Fortran, for linear algebra operation
as: Blas, OpenBlas or Intel Math Kernel Library (MKL).</p>
<dl class="py method">
<dt id="isanet.neural_network.MLPRegressor.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">X_train</span></em>, <em class="sig-param"><span class="n">Y_train</span></em>, <em class="sig-param"><span class="n">X_val</span></em>, <em class="sig-param"><span class="n">Y_val</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model to data matrix X_train and target(s) Y_train and
evaluates it on the validation set (X_val, Y_val).</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPRegressor.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the multi-layer perceptron classifier.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPRegressor.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the parameters of the multi-layer perceptron.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPRegressor.get_history">
<code class="sig-name descname">get_history</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor.get_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the history of the multi-layer perceptron.</p>
</dd></dl>

<dl class="py method">
<dt id="isanet.neural_network.MLPRegressor.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#isanet.neural_network.MLPRegressor.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the weights of the multi-layer perceptron.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="isanet.optimizer.html" class="btn btn-neutral float-right" title="isanet.optimizer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="isanet.model_selection.html" class="btn btn-neutral float-left" title="isanet.model_selection" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Alessandro Cudazzo, Giulia Volpi

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>